{
  "cells": [
   {
    "cell_type": "markdown",
    "metadata": {},
    "source": [
     "# Pinecone Quickstart\n",
     "\n",
     "This notebook introduces the basics of working with Pinecone, a serverless vector database. You'll learn how to:\n",
     "\n",
     "1. Connect to Pinecone\n",
     "2. Create an index\n",
     "3. Upsert vectors\n",
     "4. Query vectors\n",
     "5. Use metadata filtering\n",
     "6. Work with namespaces\n",
     "7. Delete vectors and indexes"
    ]
   },
   {
    "cell_type": "markdown",
    "metadata": {},
    "source": [
     "## Setup\n",
     "\n",
     "First, make sure you have your Pinecone API key set as an environment variable named `PINECONE_API_KEY`. \n",
     "\n",
     "Let's import the necessary libraries:"
    ]
   },
   {
    "cell_type": "code",
    "execution_count": null,
    "metadata": {},
    "outputs": [],
    "source": [
     "import os\n",
     "import time\n",
     "import uuid\n",
     "import numpy as np\n",
     "\n",
     "from pinecone import Pinecone, ServerlessSpec\n",
     "\n",
     "# Check if the API key is set\n",
     "api_key = os.environ.get(\"PINECONE_API_KEY\")\n",
     "if not api_key:\n",
     "    raise ValueError(\"PINECONE_API_KEY environment variable not set\")\n",
     "\n",
     "# Initialize the Pinecone client\n",
     "pc = Pinecone(api_key=api_key)\n",
     "print(\"Successfully connected to Pinecone!\")"
    ]
   },
   {
    "cell_type": "markdown",
    "metadata": {},
    "source": [
     "## 1. Creating an Index\n",
     "\n",
     "Let's create a serverless index with the following parameters:\n",
     "- Dimension: 768 (matches many embedding models)\n",
     "- Metric: cosine similarity\n",
     "- Cloud: AWS\n",
     "- Region: us-east-1"
    ]
   },
   {
    "cell_type": "code",
    "execution_count": null,
    "metadata": {},
    "outputs": [],
    "source": [
     "# Create a unique index name\n",
     "unique_id = str(uuid.uuid4())[:8]\n",
     "index_name = f\"quickstart-{unique_id}\"\n",
     "\n",
     "# Default settings\n",
     "DIMENSION = 768\n",
     "METRIC = \"cosine\"\n",
     "CLOUD = \"aws\"\n",
     "REGION = \"us-east-1\"\n",
     "\n",
     "# Check if the index already exists\n",
     "if pc.has_index(index_name):\n",
     "    print(f\"Index {index_name} already exists\")\n",
     "else:\n",
     "    # Create the index\n",
     "    print(f\"Creating index: {index_name}\")\n",
     "    pc.create_index(\n",
     "        name=index_name,\n",
     "        vector_type=\"dense\",\n",
     "        dimension=DIMENSION,\n",
     "        metric=METRIC,\n",
     "        spec=ServerlessSpec(\n",
     "            cloud=CLOUD,\n",
     "            region=REGION\n",
     "        )\n",
     "    )\n",
     "    \n",
     "    # Wait for the index to be ready\n",
     "    print(\"Waiting for index to be ready...\")\n",
     "    while True:\n",
     "        try:\n",
     "            status = pc.describe_index(index_name).status\n",
     "            if status['ready']:\n",
     "                print(f\"Index {index_name} is ready\")\n",
     "                break\n",
     "            else:\n",
     "                print(\"Still waiting...\")\n",
     "                time.sleep(5)\n",
     "        except Exception as e:\n",
     "            print(f\"Error checking index status: {e}\")\n",
     "            time.sleep(2)"
    ]
   },
   {
    "cell_type": "markdown",
    "metadata": {},
    "source": [
     "## 2. Creating Sample Vectors\n",
     "\n",
     "Let's create some random vectors to use in our examples. We'll normalize them to ensure they have unit length."
    ]
   },
   {
    "cell_type": "code",
    "execution_count": null,
    "metadata": {},
    "outputs": [],
    "source": [
     "def create_random_vectors(count, dim):\n",
     "    \"\"\"Create random normalized vectors for testing.\"\"\"\n",
     "    vectors = np.random.rand(count, dim).astype(np.float32)\n",
     "    # Normalize vectors to unit length\n",
     "    vectors = vectors / np.linalg.norm(vectors, axis=1, keepdims=True)\n",
     "    return vectors.tolist()\n",
     "\n",
     "# Generate 100 random vectors\n",
     "vector_count = 100\n",
     "vectors = create_random_vectors(vector_count, DIMENSION)\n",
     "\n",
     "# Create vector records with IDs and metadata\n",
     "vector_data = [\n",
     "    {\n",
     "        \"id\": f\"vec-{i}\",\n",
     "        \"values\": vectors[i],\n",
     "        \"metadata\": {\n",
     "            \"category\": f\"category-{i % 5}\",  # Creates 5 categories\n",
     "            \"score\": round(np.random.random(), 2),  # Random score between 0 and 1\n",
     "            \"is_valid\": bool(i % 2)  # Alternates between True and False\n",
     "        }\n",
     "    }\n",
     "    for i in range(vector_count)\n",
     "]\n",
     "\n",
     "print(f\"Created {vector_count} sample vectors\")\n",
     "print(f\"Sample vector structure: {vector_data[0]}\")"
    ]
   },
   {
    "cell_type": "markdown",
    "metadata": {},
    "source": [
     "## 3. Upserting Vectors\n",
     "\n",
     "Now let's upsert (insert or update) the vectors into our index."
    ]
   },
   {
    "cell_type": "code",
    "execution_count": null,
    "metadata": {},
    "outputs": [],
    "source": [
     "# Get the index\n",
     "index = pc.index(index_name)\n",
     "\n",
     "# Upsert in batches of 100 (max batch size)\n",
     "batch_size = 100\n",
     "for i in range(0, len(vector_data), batch_size):\n",
     "    batch = vector_data[i:i+batch_size]\n",
     "    index.upsert(vectors=batch)\n",
     "    print(f\"Upserted vectors {i} to {i+len(batch)-1}\")\n",
     "\n",
     "# Allow time for indexing\n",
     "time.sleep(2)\n",
     "\n",
     "# Check vector count\n",
     "stats = index.describe_index_stats()\n",
     "print(f\"Total vectors in index: {stats.namespaces.get('', {}).get('vector_count', 0)}\")"
    ]
   },
   {
    "cell_type": "markdown",
    "metadata": {},
    "source": [
     "## 4. Basic Vector Query\n",
     "\n",
     "Let's perform a simple vector query to find similar vectors."
    ]
   },
   {
    "cell_type": "code",
    "execution_count": null,
    "metadata": {},
    "outputs": [],
    "source": [
     "# Pick a random vector to query with\n",
     "query_idx = np.random.randint(0, len(vector_data))\n",
     "query_vector = vector_data[query_idx][\"values\"]\n",
     "query_id = vector_data[query_idx][\"id\"]\n",
     "\n",
     "print(f\"Querying with vector {query_id}\")\n",
     "\n",
     "# Perform the query\n",
     "results = index.query(\n",
     "    vector=query_vector,\n",
     "    top_k=5,  # Return top 5 matches\n",
     "    include_metadata=True\n",
     ")\n",
     "\n",
     "# Print results\n",
     "print(f\"\\nQuery results for {query_id}:\")\n",
     "for match in results.matches:\n",
     "    print(f\"ID: {match.id}, Score: {match.score:.4f}\")\n",
     "    if match.metadata:\n",
     "        print(f\"Metadata: {match.metadata}\")\n",
     "    print()"
    ]
   },
   {
    "cell_type": "markdown",
    "metadata": {},
    "source": [
     "## 5. Metadata Filtering\n",
     "\n",
     "Pinecone allows you to filter query results based on metadata."
    ]
   },
   {
    "cell_type": "code",
    "execution_count": null,
    "metadata": {},
    "outputs": [],
    "source": [
     "# Query with metadata filter for category-0\n",
     "filter_results = index.query(\n",
     "    vector=query_vector,\n",
     "    top_k=5,\n",
     "    include_metadata=True,\n",
     "    filter={\n",
     "        \"category\": {\"$eq\": \"category-0\"}\n",
     "    }\n",
     ")\n",
     "\n",
     "print(f\"\\nQuery results with filter for category-0:\")\n",
     "for match in filter_results.matches:\n",
     "    print(f\"ID: {match.id}, Score: {match.score:.4f}\")\n",
     "    if match.metadata:\n",
     "        print(f\"Metadata: {match.metadata}\")\n",
     "    print()\n",
     "\n",
     "# More complex filter: score > 0.5 AND is_valid = True\n",
     "complex_filter_results = index.query(\n",
     "    vector=query_vector,\n",
     "    top_k=5,\n",
     "    include_metadata=True,\n",
     "    filter={\n",
     "        \"$and\": [\n",
     "            {\"score\": {\"$gt\": 0.5}},\n",
     "            {\"is_valid\": True}\n",
     "        ]\n",
     "    }\n",
     ")\n",
     "\n",
     "print(f\"\\nQuery results with complex filter (score > 0.5 AND is_valid = True):\")\n",
     "for match in complex_filter_results.matches:\n",
     "    print(f\"ID: {match.id}, Score: {match.score:.4f}\")\n",
     "    if match.metadata:\n",
     "        print(f\"Metadata: {match.metadata}\")\n",
     "    print()"
    ]
   },
   {
    "cell_type": "markdown",
    "metadata": {},
    "source": [
     "## 6. Working with Namespaces\n",
     "\n",
     "Namespaces allow you to partition your data within an index."
    ]
   },
   {
    "cell_type": "code",
    "execution_count": null,
    "metadata": {},
    "outputs": [],
    "source": [
     "# Create new vectors for a different namespace\n",
     "namespace_vectors = create_random_vectors(50, DIMENSION)\n",
     "namespace_data = [\n",
     "    {\n",
     "        \"id\": f\"ns-vec-{i}\",\n",
     "        \"values\": namespace_vectors[i],\n",
     "        \"metadata\": {\n",
     "            \"namespace\": \"test-namespace\",\n",
     "            \"value\": round(np.random.random(), 2)\n",
     "        }\n",
     "    }\n",
     "    for i in range(50)\n",
     "]\n",
     "\n",
     "# Upsert to the new namespace\n",
     "index.upsert(vectors=namespace_data, namespace=\"test-namespace\")\n",
     "print(\"Upserted vectors to 'test-namespace'\")\n",
     "\n",
     "# Allow time for indexing\n",
     "time.sleep(2)\n",
     "\n",
     "# Check namespace statistics\n",
     "stats = index.describe_index_stats()\n",
     "print(\"\\nNamespace Statistics:\")\n",
     "for ns_name, ns_stats in stats.namespaces.items():\n",
     "    ns_display = ns_name if ns_name else \"default\"\n",
     "    print(f\"Namespace: {ns_display}, Vector Count: {ns_stats.vector_count}\")\n",
     "    \n",
     "# Query in the new namespace\n",
     "query_vector = namespace_data[0][\"values\"]\n",
     "query_id = namespace_data[0][\"id\"]\n",
     "\n",
     "namespace_results = index.query(\n",
     "    vector=query_vector,\n",
     "    top_k=3,\n",
     "    include_metadata=True,\n",
     "    namespace=\"test-namespace\"\n",
     ")\n",
     "\n",
     "print(f\"\\nQuery results in 'test-namespace':\")\n",
     "for match in namespace_results.matches:\n",
     "    print(f\"ID: {match.id}, Score: {match.score:.4f}\")\n",
     "    if match.metadata:\n",
     "        print(f\"Metadata: {match.metadata}\")\n",
     "    print()"
    ]
   },
   {
    "cell_type": "markdown",
    "metadata": {},
    "source": [
     "## 7. Deleting Vectors\n",
     "\n",
     "Now let's delete some vectors from our index."
    ]
   },
   {
    "cell_type": "code",
    "execution_count": null,
    "metadata": {},
    "outputs": [],
    "source": [
     "# Delete 5 random vectors from the default namespace\n",
     "delete_indices = np.random.choice(len(vector_data), 5, replace=False)\n",
     "ids_to_delete = [vector_data[i][\"id\"] for i in delete_indices]\n",
     "\n",
     "print(f\"Deleting vectors: {ids_to_delete}\")\n",
     "index.delete(ids=ids_to_delete)\n",
     "\n",
     "# Allow time for deletion to process\n",
     "time.sleep(2)\n",
     "\n",
     "# Check vector count after deletion\n",
     "stats = index.describe_index_stats()\n",
     "print(f\"Vectors in default namespace after deletion: {stats.namespaces.get('', {}).get('vector_count', 0)}\")\n",
     "\n",
     "# Delete all vectors in the test namespace\n",
     "print(\"\\nDeleting all vectors in 'test-namespace'\")\n",
     "index.delete(delete_all=True, namespace=\"test-namespace\")\n",
     "\n",
     "# Allow time for deletion to process\n",
     "time.sleep(2)\n",
     "\n",
     "# Check namespace statistics after deletion\n",
     "stats = index.describe_index_stats()\n",
     "print(\"\\nNamespace Statistics after deletion:\")\n",
     "for ns_name, ns_stats in stats.namespaces.items():\n",
     "    ns_display = ns_name if ns_name else \"default\"\n",
     "    print(f\"Namespace: {ns_display}, Vector Count: {ns_stats.vector_count}\")"
    ]
   },
   {
    "cell_type": "markdown",
    "metadata": {},
    "source": [
     "## 8. Cleaning Up\n",
     "\n",
     "Finally, let's delete our index to clean up resources. Uncomment the cell below to run it."
    ]
   },
   {
    "cell_type": "code",
    "execution_count": null,
    "metadata": {},
    "outputs": [],
    "source": [
     "# Uncomment to delete the index\n",
     "# print(f\"Deleting index: {index_name}\")\n",
     "# pc.delete_index(index_name)\n",
     "# print(f\"Index {index_name} deleted\")"
    ]
   },
   {
    "cell_type": "markdown",
    "metadata": {},
    "source": [
     "## Summary\n",
     "\n",
     "In this notebook, you've learned the basics of working with Pinecone:\n",
     "\n",
     "- Creating a serverless index\n",
     "- Upserting vectors with metadata\n",
     "- Querying vectors and understanding similarity scores\n",
     "- Filtering query results using metadata filters\n",
     "- Working with namespaces to partition your data\n",
     "- Deleting vectors and indexes\n",
     "\n",
     "These foundational concepts will help you build more complex applications with Pinecone."
    ]
   }
  ],
  "metadata": {
   "kernelspec": {
    "display_name": "Python 3",
    "language": "python",
    "name": "python3"
   },
   "language_info": {
    "codemirror_mode": {
     "name": "ipython",
     "version": 3
    },
    "file_extension": ".py",
    "mimetype": "text/x-python",
    "name": "python",
    "nbconvert_exporter": "python",
    "pygments_lexer": "ipython3",
    "version": "3.10.12"
   }
  },
  "nbformat": 4,
  "nbformat_minor": 4
 }