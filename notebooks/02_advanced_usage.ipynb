{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e3d4fd",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "{\n",
    " \"cells\": [\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# Advanced Pinecone Usage\\n\",\n",
    "    \"\\n\",\n",
    "    \"This notebook demonstrates advanced techniques with Pinecone vector database, including:\\n\",\n",
    "    \"- Working with multiple indexes\\n\",\n",
    "    \"- Multi-modal vectors\\n\",\n",
    "    \"- Advanced metadata filtering\\n\",\n",
    "    \"- Query-time vector transformations\\n\",\n",
    "    \"- Performance optimization\\n\",\n",
    "    \"- Index monitoring\\n\",\n",
    "    \"\\n\",\n",
    "    \"Let's start by setting up our environment.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"import os\\n\",\n",
    "    \"import time\\n\",\n",
    "    \"import uuid\\n\",\n",
    "    \"import numpy as np\\n\",\n",
    "    \"import pandas as pd\\n\",\n",
    "    \"import matplotlib.pyplot as plt\\n\",\n",
    "    \"from typing import List, Dict, Any, Optional\\n\",\n",
    "    \"from sklearn.decomposition import PCA\\n\",\n",
    "    \"from sentence_transformers import SentenceTransformer\\n\",\n",
    "    \"\\n\",\n",
    "    \"from pinecone import Pinecone, ServerlessSpec\\n\",\n",
    "    \"from src.config import (DEFAULT_CLOUD, DEFAULT_DIMENSION, DEFAULT_METRIC, DEFAULT_REGION)\\n\",\n",
    "    \"from src.utils import (get_pinecone_client, create_random_vectors, wait_for_index_ready, clean_up_index)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 1. Working with Multiple Indexes\\n\",\n",
    "    \"\\n\",\n",
    "    \"In some applications, you may need to work with multiple indexes for different types of data or different embedding models. Here's how to manage multiple indexes efficiently.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"def create_multiple_indexes(count: int = 2, dims: List[int] = None):\\n\",\n",
    "    \"    \\\"\\\"\\\"Create multiple indexes with different dimensions.\\\"\\\"\\\"\\n\",\n",
    "    \"    pc = get_pinecone_client()\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Use default dimension if none provided\\n\",\n",
    "    \"    if not dims:\\n\",\n",
    "    \"        dims = [DEFAULT_DIMENSION] * count\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    index_names = []\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    for i in range(count):\\n\",\n",
    "    \"        # Create a unique index name\\n\",\n",
    "    \"        unique_id = str(uuid.uuid4())[:8]\\n\",\n",
    "    \"        index_name = f\\\"multi-index-{i}-{unique_id}\\\"\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        # Check if index already exists\\n\",\n",
    "    \"        if pc.has_index(index_name):\\n\",\n",
    "    \"            print(f\\\"Index {index_name} already exists, skipping creation\\\")\\n\",\n",
    "    \"            index_names.append(index_name)\\n\",\n",
    "    \"            continue\\n\",\n",
    "    \"            \\n\",\n",
    "    \"        # Create a new serverless index with specified dimension\\n\",\n",
    "    \"        print(f\\\"Creating index {i+1}/{count}: {index_name} with dimension {dims[i]}\\\")\\n\",\n",
    "    \"        pc.create_index(\\n\",\n",
    "    \"            name=index_name,\\n\",\n",
    "    \"            vector_type=\\\"dense\\\",\\n\",\n",
    "    \"            dimension=dims[i],\\n\",\n",
    "    \"            metric=DEFAULT_METRIC,\\n\",\n",
    "    \"            spec=ServerlessSpec(\\n\",\n",
    "    \"                cloud=DEFAULT_CLOUD,\\n\",\n",
    "    \"                region=DEFAULT_REGION\\n\",\n",
    "    \"            )\\n\",\n",
    "    \"        )\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        # Wait for the index to be ready\\n\",\n",
    "    \"        wait_for_index_ready(pc, index_name)\\n\",\n",
    "    \"        index_names.append(index_name)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    return index_names\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Create two indexes with different dimensions\\n\",\n",
    "    \"index_names = create_multiple_indexes(2, [384, 768])  # Common dimensions for different models\\n\",\n",
    "    \"print(f\\\"Created indexes: {index_names}\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"### Populating Each Index with Appropriate Vectors\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"def populate_indexes(index_names: List[str], dimensions: List[int], vector_count: int = 50):\\n\",\n",
    "    \"    \\\"\\\"\\\"Populate each index with appropriate dimensional vectors.\\\"\\\"\\\"\\n\",\n",
    "    \"    pc = get_pinecone_client()\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    for idx, (index_name, dim) in enumerate(zip(index_names, dimensions)):\\n\",\n",
    "    \"        index = pc.index(index_name)\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        # Create random vectors with the appropriate dimension\\n\",\n",
    "    \"        vectors = create_random_vectors(vector_count, dim)\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        # Prepare vector data with ids and metadata\\n\",\n",
    "    \"        vector_data = [\\n\",\n",
    "    \"            {\\n\",\n",
    "    \"                \\\"id\\\": f\\\"vec-idx{idx}-{i}\\\",\\n\",\n",
    "    \"                \\\"values\\\": vectors[i],\\n\",\n",
    "    \"                \\\"metadata\\\": {\\n\",\n",
    "    \"                    \\\"index\\\": idx,\\n\",\n",
    "    \"                    \\\"dimension\\\": dim,\\n\",\n",
    "    \"                    \\\"category\\\": f\\\"category-{i % 3}\\\",\\n\",\n",
    "    \"                    \\\"priority\\\": i % 5,\\n\",\n",
    "    \"                    \\\"timestamp\\\": time.time() - (i * 3600)  # Different timestamps\\n\",\n",
    "    \"                }\\n\",\n",
    "    \"            }\\n\",\n",
    "    \"            for i in range(vector_count)\\n\",\n",
    "    \"        ]\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        # Upsert in batches\\n\",\n",
    "    \"        batch_size = 25\\n\",\n",
    "    \"        for i in range(0, len(vector_data), batch_size):\\n\",\n",
    "    \"            batch = vector_data[i:i+batch_size]\\n\",\n",
    "    \"            index.upsert(vectors=batch)\\n\",\n",
    "    \"            print(f\\\"Index {index_name}: Upserted vectors {i} to {i+len(batch)-1}\\\")\\n\",\n",
    "    \"            \\n\",\n",
    "    \"        # Check vector count\\n\",\n",
    "    \"        time.sleep(2)  # Allow time for indexing\\n\",\n",
    "    \"        stats = index.describe_index_stats()\\n\",\n",
    "    \"        print(f\\\"Index {index_name}: Total vectors: {stats.namespaces.get('', {}).get('vector_count', 0)}\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Populate the indexes\\n\",\n",
    "    \"populate_indexes(index_names, [384, 768], 50)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 2. Multi-Modal Vectors\\n\",\n",
    "    \"\\n\",\n",
    "    \"Multi-modal vectors involve using different embedding models for different types of content (text, images, etc.). Here we'll simulate working with multi-modal data.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"def simulate_multimodal_vectors(text_samples: List[str]):\\n\",\n",
    "    \"    \\\"\\\"\\\"Simulate text and image vectors using SentenceTransformer.\\\"\\\"\\\"\\n\",\n",
    "    \"    # Create a sentence transformer model for text embeddings\\n\",\n",
    "    \"    text_model = SentenceTransformer('all-MiniLM-L6-v2')  # 384 dimensions\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Get text embeddings\\n\",\n",
    "    \"    text_embeddings = text_model.encode(text_samples)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Simulate image embeddings with random vectors (in real apps, you'd use a vision model)\\n\",\n",
    "    \"    image_embeddings = create_random_vectors(len(text_samples), 512)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    return {\\n\",\n",
    "    \"        \\\"text\\\": text_embeddings.tolist(),\\n\",\n",
    "    \"        \\\"image\\\": image_embeddings\\n\",\n",
    "    \"    }\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Sample text data\\n\",\n",
    "    \"text_samples = [\\n\",\n",
    "    \"    \\\"A red sports car parked by the beach\\\",\\n\",\n",
    "    \"    \\\"A dog playing in the park\\\",\\n\",\n",
    "    \"    \\\"A cityscape at night with bright lights\\\",\\n\",\n",
    "    \"    \\\"A plate of pasta with tomato sauce\\\",\\n\",\n",
    "    \"    \\\"A person hiking on a mountain trail\\\"\\n\",\n",
    "    \"]\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Generate embeddings\\n\",\n",
    "    \"multimodal_vectors = simulate_multimodal_vectors(text_samples)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Print shapes\\n\",\n",
    "    \"print(f\\\"Text vectors shape: {len(multimodal_vectors['text'])} x {len(multimodal_vectors['text'][0])}\\\")\\n\",\n",
    "    \"print(f\\\"Image vectors shape: {len(multimodal_vectors['image'])} x {len(multimodal_vectors['image'][0])}\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"### Creating a Multi-Modal Index and Upserting Data\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"def create_multimodal_index():\\n\",\n",
    "    \"    \\\"\\\"\\\"Create an index for multi-modal vectors.\\\"\\\"\\\"\\n\",\n",
    "    \"    pc = get_pinecone_client()\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Create a unique index name\\n\",\n",
    "    \"    unique_id = str(uuid.uuid4())[:8]\\n\",\n",
    "    \"    index_name = f\\\"multimodal-{unique_id}\\\"\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Check if index already exists\\n\",\n",
    "    \"    if pc.has_index(index_name):\\n\",\n",
    "    \"        print(f\\\"Index {index_name} already exists, skipping creation\\\")\\n\",\n",
    "    \"        return index_name\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # For multi-modal, we'll use a dimension that can fit all our vectors\\n\",\n",
    "    \"    # We'll use a technique called \\\"vector concatenation\\\" for demonstration\\n\",\n",
    "    \"    # In real applications, you might use separate indexes or more sophisticated techniques\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Create a new serverless index with dimension that fits both text and image vectors\\n\",\n",
    "    \"    # We'll pad the smaller vectors\\n\",\n",
    "    \"    combined_dim = 1024  # Large enough for both types after padding\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    print(f\\\"Creating multi-modal index: {index_name}\\\")\\n\",\n",
    "    \"    pc.create_index(\\n\",\n",
    "    \"        name=index_name,\\n\",\n",
    "    \"        vector_type=\\\"dense\\\", \\n\",\n",
    "    \"        dimension=combined_dim,\\n\",\n",
    "    \"        metric=DEFAULT_METRIC,\\n\",\n",
    "    \"        spec=ServerlessSpec(\\n\",\n",
    "    \"            cloud=DEFAULT_CLOUD,\\n\",\n",
    "    \"            region=DEFAULT_REGION\\n\",\n",
    "    \"        )\\n\",\n",
    "    \"    )\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Wait for the index to be ready\\n\",\n",
    "    \"    wait_for_index_ready(pc, index_name)\\n\",\n",
    "    \"    return index_name\\n\",\n",
    "    \"\\n\",\n",
    "    \"def pad_vector(vector: List[float], target_dim: int) -> List[float]:\\n\",\n",
    "    \"    \\\"\\\"\\\"Pad a vector to the target dimension with zeros.\\\"\\\"\\\"\\n\",\n",
    "    \"    if len(vector) >= target_dim:\\n\",\n",
    "    \"        return vector[:target_dim]\\n\",\n",
    "    \"    return vector + [0.0] * (target_dim - len(vector))\\n\",\n",
    "    \"\\n\",\n",
    "    \"def upsert_multimodal_data(index_name: str, text_vectors: List[List[float]], \\n\",\n",
    "    \"                          image_vectors: List[List[float]], descriptions: List[str]):\\n\",\n",
    "    \"    \\\"\\\"\\\"Upsert multi-modal vectors with appropriate metadata.\\\"\\\"\\\"\\n\",\n",
    "    \"    pc = get_pinecone_client()\\n\",\n",
    "    \"    index = pc.index(index_name)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    target_dim = 1024\\n\",\n",
    "    \"    vector_data = []\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Create text vector records\\n\",\n",
    "    \"    for i, (text_vec, desc) in enumerate(zip(text_vectors, descriptions)):\\n\",\n",
    "    \"        padded_vec = pad_vector(text_vec, target_dim)\\n\",\n",
    "    \"        vector_data.append({\\n\",\n",
    "    \"            \\\"id\\\": f\\\"text-{i}\\\",\\n\",\n",
    "    \"            \\\"values\\\": padded_vec,\\n\",\n",
    "    \"            \\\"metadata\\\": {\\n\",\n",
    "    \"                \\\"type\\\": \\\"text\\\",\\n\",\n",
    "    \"                \\\"description\\\": desc,\\n\",\n",
    "    \"                \\\"original_dim\\\": len(text_vec)\\n\",\n",
    "    \"            }\\n\",\n",
    "    \"        })\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Create image vector records\\n\",\n",
    "    \"    for i, (img_vec, desc) in enumerate(zip(image_vectors, descriptions)):\\n\",\n",
    "    \"        padded_vec = pad_vector(img_vec, target_dim)\\n\",\n",
    "    \"        vector_data.append({\\n\",\n",
    "    \"            \\\"id\\\": f\\\"image-{i}\\\",\\n\",\n",
    "    \"            \\\"values\\\": padded_vec,\\n\",\n",
    "    \"            \\\"metadata\\\": {\\n\",\n",
    "    \"                \\\"type\\\": \\\"image\\\",\\n\",\n",
    "    \"                \\\"description\\\": desc,\\n\",\n",
    "    \"                \\\"original_dim\\\": len(img_vec)\\n\",\n",
    "    \"            }\\n\",\n",
    "    \"        })\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Upsert all vector data\\n\",\n",
    "    \"    index.upsert(vectors=vector_data)\\n\",\n",
    "    \"    print(f\\\"Upserted {len(vector_data)} multi-modal vectors\\\")\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Check vector count\\n\",\n",
    "    \"    time.sleep(2)  # Allow time for indexing\\n\",\n",
    "    \"    stats = index.describe_index_stats()\\n\",\n",
    "    \"    print(f\\\"Total vectors in index: {stats.namespaces.get('', {}).get('vector_count', 0)}\\\")\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    return vector_data\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Create multimodal index\\n\",\n",
    "    \"multimodal_index = create_multimodal_index()\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Upsert multimodal data\\n\",\n",
    "    \"multimodal_data = upsert_multimodal_data(\\n\",\n",
    "    \"    multimodal_index, \\n\",\n",
    "    \"    multimodal_vectors['text'], \\n\",\n",
    "    \"    multimodal_vectors['image'],\\n\",\n",
    "    \"    text_samples\\n\",\n",
    "    \")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 3. Advanced Metadata Filtering\\n\",\n",
    "    \"\\n\",\n",
    "    \"Pinecone allows for sophisticated metadata filtering. Let's explore complex filter expressions.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"def advanced_metadata_filtering(index_name: str):\\n\",\n",
    "    \"    \\\"\\\"\\\"Demonstrate advanced metadata filtering techniques.\\\"\\\"\\\"\\n\",\n",
    "    \"    pc = get_pinecone_client()\\n\",\n",
    "    \"    index = pc.index(index_name)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Get a random vector to use as query\\n\",\n",
    "    \"    query_vector = create_random_vectors(1, 1024)[0]\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    print(\\\"\\\\n--- Advanced Metadata Filtering Examples ---\\\")\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # 1. Filter by exact match\\n\",\n",
    "    \"    filter_exact = {\\\"type\\\": \\\"text\\\"}\\n\",\n",
    "    \"    results_exact = index.query(\\n\",\n",
    "    \"        vector=query_vector,\\n\",\n",
    "    \"        filter=filter_exact,\\n\",\n",
    "    \"        top_k=3,\\n\",\n",
    "    \"        include_metadata=True\\n\",\n",
    "    \"    )\\n\",\n",
    "    \"    print(\\\"\\\\n1. Filter by exact match (type='text'):\\\")\\n\",\n",
    "    \"    for i, match in enumerate(results_exact.matches):\\n\",\n",
    "    \"        print(f\\\"  {i+1}. ID: {match.id}, Score: {match.score:.4f}, Metadata: {match.metadata}\\\")\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # 2. Range filtering with $gt, $gte, $lt, $lte\\n\",\n",
    "    \"    # In this example we'll use the timestamps we'd create in a real scenario\\n\",\n",
    "    \"    # Create some timestamp-based vector data first\\n\",\n",
    "    \"    timestamp_vectors = []\\n\",\n",
    "    \"    current_time = time.time()\\n\",\n",
    "    \"    for i in range(20):\\n\",\n",
    "    \"        # Create vectors with timestamps spread over the last 30 days\\n\",\n",
    "    \"        timestamp = current_time - (i * 86400 * 1.5)  # Approx. 1.5 days apart\\n\",\n",
    "    \"        timestamp_vectors.append({\\n\",\n",
    "    \"            \\\"id\\\": f\\\"time-{i}\\\",\\n\",\n",
    "    \"            \\\"values\\\": create_random_vectors(1, 1024)[0],\\n\",\n",
    "    \"            \\\"metadata\\\": {\\n\",\n",
    "    \"                \\\"timestamp\\\": timestamp,\\n\",\n",
    "    \"                \\\"priority\\\": i % 5,\\n\",\n",
    "    \"                \\\"category\\\": f\\\"cat-{i % 3}\\\"\\n\",\n",
    "    \"            }\\n\",\n",
    "    \"        })\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Upsert these vectors\\n\",\n",
    "    \"    index.upsert(vectors=timestamp_vectors)\\n\",\n",
    "    \"    time.sleep(2)  # Allow time for indexing\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Now query with range filters\\n\",\n",
    "    \"    one_week_ago = current_time - (7 * 86400)\\n\",\n",
    "    \"    filter_range = {\\\"timestamp\\\": {\\\"$gte\\\": one_week_ago}}\\n\",\n",
    "    \"    results_range = index.query(\\n\",\n",
    "    \"        vector=query_vector,\\n\",\n",
    "    \"        filter=filter_range,\\n\",\n",
    "    \"        top_k=3,\\n\",\n",
    "    \"        include_metadata=True\\n\",\n",
    "    \"    )\\n\",\n",
    "    \"    print(\\\"\\\\n2. Range filtering (timestamp >= 1 week ago):\\\")\\n\",\n",
    "    \"    for i, match in enumerate(results_range.matches):\\n\",\n",
    "    \"        print(f\\\"  {i+1}. ID: {match.id}, Score: {match.score:.4f}\\\")\\n\",\n",
    "    \"        print(f\\\"     Timestamp: {time.ctime(match.metadata['timestamp'])}\\\")\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # 3. Combining filters with $and, $or\\n\",\n",
    "    \"    filter_combined = {\\n\",\n",
    "    \"        \\\"$and\\\": [\\n\",\n",
    "    \"            {\\\"timestamp\\\": {\\\"$gte\\\": one_week_ago}},\\n\",\n",
    "    \"            {\\\"$or\\\": [\\n\",\n",
    "    \"                {\\\"priority\\\": {\\\"$lt\\\": 2}},\\n\",\n",
    "    \"                {\\\"category\\\": \\\"cat-1\\\"}\\n\",\n",
    "    \"            ]}\\n\",\n",
    "    \"        ]\\n\",\n",
    "    \"    }\\n\",\n",
    "    \"    results_combined = index.query(\\n\",\n",
    "    \"        vector=query_vector,\\n\",\n",
    "    \"        filter=filter_combined,\\n\",\n",
    "    \"        top_k=3,\\n\",\n",
    "    \"        include_metadata=True\\n\",\n",
    "    \"    )\\n\",\n",
    "    \"    print(\\\"\\\\n3. Combined filtering (recent AND (high priority OR specific category)):\\\")\\n\",\n",
    "    \"    for i, match in enumerate(results_combined.matches):\\n\",\n",
    "    \"        print(f\\\"  {i+1}. ID: {match.id}, Score: {match.score:.4f}\\\")\\n\",\n",
    "    \"        print(f\\\"     Priority: {match.metadata['priority']}, Category: {match.metadata['category']}\\\")\\n\",\n",
    "    \"        print(f\\\"     Timestamp: {time.ctime(match.metadata['timestamp'])}\\\")\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # 4. Using $in operator for multiple values\\n\",\n",
    "    \"    filter_in = {\\n\",\n",
    "    \"        \\\"$and\\\": [\\n\",\n",
    "    \"            {\\\"category\\\": {\\\"$in\\\": [\\\"cat-0\\\", \\\"cat-2\\\"]}},\\n\",\n",
    "    \"            {\\\"priority\\\": {\\\"$in\\\": [0, 3, 4]}}\\n\",\n",
    "    \"        ]\\n\",\n",
    "    \"    }\\n\",\n",
    "    \"    results_in = index.query(\\n\",\n",
    "    \"        vector=query_vector,\\n\",\n",
    "    \"        filter=filter_in,\\n\",\n",
    "    \"        top_k=3,\\n\",\n",
    "    \"        include_metadata=True\\n\",\n",
    "    \"    )\\n\",\n",
    "    \"    print(\\\"\\\\n4. Using $in operator (category in [cat-0, cat-2] AND priority in [0, 3, 4]):\\\")\\n\",\n",
    "    \"    for i, match in enumerate(results_in.matches):\\n\",\n",
    "    \"        print(f\\\"  {i+1}. ID: {match.id}, Score: {match.score:.4f}\\\")\\n\",\n",
    "    \"        print(f\\\"     Priority: {match.metadata['priority']}, Category: {match.metadata['category']}\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Run advanced metadata filtering examples on our multimodal index\\n\",\n",
    "    \"advanced_metadata_filtering(multimodal_index)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 4. Query-Time Vector Transformations\\n\",\n",
    "    \"\\n\",\n",
    "    \"Sometimes you need to transform vectors at query time. This can include:\\n\",\n",
    "    \"- Normalization\\n\",\n",
    "    \"- Dimensionality reduction\\n\",\n",
    "    \"- Vector blending or interpolation\\n\",\n",
    "    \"\\n\",\n",
    "    \"Let's implement some of these techniques.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"def normalize_vector(vector: List[float]) -> List[float]:\\n\",\n",
    "    \"    \\\"\\\"\\\"Normalize a vector to unit length.\\\"\\\"\\\"\\n\",\n",
    "    \"    array = np.array(vector)\\n\",\n",
    "    \"    norm = np.linalg.norm(array)\\n\",\n",
    "    \"    if norm == 0:\\n\",\n",
    "    \"        return vector\\n\",\n",
    "    \"    return (array / norm).tolist()\\n\",\n",
    "    \"\\n\",\n",
    "    \"def reduce_dimensions(vectors: List[List[float]], target_dim: int) -> List[List[float]]:\\n\",\n",
    "    \"    \\\"\\\"\\\"Reduce dimensionality using PCA.\\\"\\\"\\\"\\n\",\n",
    "    \"    pca = PCA(n_components=target_dim)\\n\",\n",
    "    \"    reduced = pca.fit_transform(vectors)\\n\",\n",
    "    \"    return reduced.tolist()\\n\",\n",
    "    \"\\n\",\n",
    "    \"def blend_vectors(vector1: List[float], vector2: List[float], weight: float = 0.5) -> List[float]:\\n\",\n",
    "    \"    \\\"\\\"\\\"Blend two vectors with a weight parameter.\\\"\\\"\\\"\\n\",\n",
    "    \"    v1 = np.array(vector1)\\n\",\n",
    "    \"    v2 = np.array(vector2)\\n\",\n",
    "    \"    blended = (weight * v1) + ((1 - weight) * v2)\\n\",\n",
    "    \"    return normalize_vector(blended.tolist())\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Generate some test vectors\\n\",\n",
    "    \"test_vectors = create_random_vectors(5, 128)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# 1. Normalize a vector\\n\",\n",
    "    \"normalized = normalize_vector(test_vectors[0])\\n\",\n",
    "    \"norm = np.linalg.norm(normalized)\\n\",\n",
    "    \"print(f\\\"Normalized vector has norm: {norm:.4f}\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# 2. Reduce dimensions\\n\",\n",
    "    \"reduced = reduce_dimensions(test_vectors, 64)\\n\",\n",
    "    \"print(f\\\"Original dimension: {len(test_vectors[0])}, Reduced dimension: {len(reduced[0])}\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# 3. Blend vectors\\n\",\n",
    "    \"blended = blend_vectors(test_vectors[0], test_vectors[1], 0.7)\\n\",\n",
    "    \"print(f\\\"Blended vector has {len(blended)} dimensions and norm: {np.linalg.norm(blended):.4f}\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"### Demonstration of Query-Time Vector Transformations\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"def query_with_transformations(index_name: str):\\n\",\n",
    "    \"    \\\"\\\"\\\"Demonstrate query-time vector transformations.\\\"\\\"\\\"\\n\",\n",
    "    \"    pc = get_pinecone_client()\\n\",\n",
    "    \"    index = pc.index(index_name)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Get stats about the index\\n\",\n",
    "    \"    stats = index.describe_index_stats()\\n\",\n",
    "    \"    print(f\\\"Index has {stats.namespaces.get('', {}).get('vector_count', 0)} vectors\\\")\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Create test vectors to query with\\n\",\n",
    "    \"    # We'll get all text vectors to work with\\n\",\n",
    "    \"    results = index.query(\\n\",\n",
    "    \"        vector=create_random_vectors(1, 1024)[0],\\n\",\n",
    "    \"        filter={\\\"type\\\": \\\"text\\\"},\\n\",\n",
    "    \"        top_k=5,\\n\",\n",
    "    \"        include_values=True,\\n\",\n",
    "    \"        include_metadata=True\\n\",\n",
    "    \"    )\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # If we got some text vectors, let's use them\\n\",\n",
    "    \"    if results.matches:\\n\",\n",
    "    \"        text_vector = results.matches[0].values\\n\",\n",
    "    \"        desc = results.matches[0].metadata.get(\\\"description\\\", \\\"Unknown\\\")\\n\",\n",
    "    \"        print(f\\\"\\\\nUsing text vector for: '{desc}'\\\")\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        # 1. Query with normalized vector\\n\",\n",
    "    \"        normalized = normalize_vector(text_vector)\\n\",\n",
    "    \"        results_norm = index.query(\\n\",\n",
    "    \"            vector=normalized,\\n\",\n",
    "    \"            top_k=3,\\n\",\n",
    "    \"            include_metadata=True\\n\",\n",
    "    \"        )\\n\",\n",
    "    \"        print(\\\"\\\\n1. Query with normalized vector:\\\")\\n\",\n",
    "    \"        for i, match in enumerate(results_norm.matches):\\n\",\n",
    "    \"            print(f\\\"  {i+1}. ID: {match.id}, Score: {match.score:.4f}\\\")\\n\",\n",
    "    \"            print(f\\\"     Description: {match.metadata.get('description', 'N/A')}\\\")\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        # 2. Blend two vectors and query\\n\",\n",
    "    \"        if len(results.matches) >= 2:\\n\",\n",
    "    \"            second_vector = results.matches[1].values\\n\",\n",
    "    \"            second_desc = results.matches[1].metadata.get(\\\"description\\\", \\\"Unknown\\\")\\n\",\n",
    "    \"            print(f\\\"\\\\nBlending with second vector: '{second_desc}'\\\")\\n\",\n",
    "    \"            \\n\",\n",
    "    \"            blended = blend_vectors(text_vector, second_vector, 0.7)\\n\",\n",
    "    \"            results_blend = index.query(\\n\",\n",
    "    \"                vector=blended,\\n\",\n",
    "    \"                top_k=3,\\n\",\n",
    "    \"                include_metadata=True\\n\",\n",
    "    \"            )\\n\",\n",
    "    \"            print(\\\"\\\\n2. Query with blended vector (70% first, 30% second):\\\")\\n\",\n",
    "    \"            for i, match in enumerate(results_blend.matches):\\n\",\n",
    "    \"                print(f\\\"  {i+1}. ID: {match.id}, Score: {match.score:.4f}\\\")\\n\",\n",
    "    \"                print(f\\\"     Description: {match.metadata.get('description', 'N/A')}\\\")\\n\",\n",
    "    \"    else:\\n\",\n",
    "    \"        print(\\\"No text vectors found in the index\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Run query transformation examples\\n\",\n",
    "    \"query_with_transformations(multimodal_index)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 5. Performance Optimization\\n\",\n",
    "    \"\\n\",\n",
    "    \"Understanding how to optimize Pinecone for performance is crucial for production applications. Let's simulate and measure query performance.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"def measure_query_performance(index_name: str, query_count: int = 10):\\n\",\n",
    "    \"    \\\"\\\"\\\"Measure query performance with different parameters.\\\"\\\"\\\"\\n\",\n",
    "    \"    pc = get_pinecone_client()\\n\",\n",
    "    \"    index = pc.index(index_name)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Create query vectors\\n\",\n",
    "    \"    query_vectors = create_random_vectors(query_count, 1024)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Scenarios to test\\n\",\n",
    "    \"    scenarios = [\\n\",\n",
    "    \"        {\\\"name\\"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
